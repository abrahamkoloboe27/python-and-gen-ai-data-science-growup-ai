{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# S√©ance 5 ‚Äî PyCaret pour prototypage rapide\n",
    "\n",
    "## üéØ Objectifs\n",
    "- Prototyper des mod√®les rapidement avec PyCaret\n",
    "- Comparer automatiquement plusieurs algorithmes\n",
    "- Interpr√©ter les r√©sultats avec des visualisations\n",
    "- Exporter et sauvegarder le meilleur mod√®le\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Introduction\n",
    "\n",
    "**PyCaret** est une biblioth√®que d'AutoML low-code qui simplifie le workflow de machine learning. Elle permet de comparer rapidement des dizaines de mod√®les et d'automatiser le preprocessing.\n",
    "\n",
    "**Installation :**\n",
    "```bash\n",
    "pip install pycaret[full]\n",
    "```\n",
    "\n",
    "**Note**: PyCaret fonctionne mieux avec un environnement isol√© (virtualenv ou conda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.classification import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-creation",
   "metadata": {},
   "source": [
    "## üìä 1. Pr√©paration des donn√©es\n",
    "\n",
    "Nous allons cr√©er un dataset de classification textuelle simplifi√©e avec des features num√©riques extraites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'un dataset avec features textuelles extraites\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "# Simuler deux types de documents: Technical vs General\n",
    "# Technical: plus long, plus de mots rares, phrases complexes\n",
    "technical_docs = {\n",
    "    'text_length': np.random.normal(2000, 500, n_samples // 2).clip(500, 5000),\n",
    "    'avg_word_length': np.random.normal(7, 1.5, n_samples // 2).clip(3, 15),\n",
    "    'num_sentences': np.random.normal(50, 15, n_samples // 2).clip(10, 150),\n",
    "    'rare_word_count': np.random.poisson(30, n_samples // 2),\n",
    "    'technical_terms': np.random.poisson(25, n_samples // 2),\n",
    "    'avg_sentence_length': np.random.normal(25, 5, n_samples // 2).clip(10, 50),\n",
    "    'unique_word_ratio': np.random.uniform(0.5, 0.8, n_samples // 2),\n",
    "    'punctuation_count': np.random.normal(100, 30, n_samples // 2).clip(20, 300),\n",
    "    'category': ['Technical'] * (n_samples // 2)\n",
    "}\n",
    "\n",
    "# General: plus court, mots simples, phrases courtes\n",
    "general_docs = {\n",
    "    'text_length': np.random.normal(800, 300, n_samples // 2).clip(200, 2000),\n",
    "    'avg_word_length': np.random.normal(5, 1, n_samples // 2).clip(3, 10),\n",
    "    'num_sentences': np.random.normal(20, 8, n_samples // 2).clip(5, 60),\n",
    "    'rare_word_count': np.random.poisson(8, n_samples // 2),\n",
    "    'technical_terms': np.random.poisson(3, n_samples // 2),\n",
    "    'avg_sentence_length': np.random.normal(15, 3, n_samples // 2).clip(8, 30),\n",
    "    'unique_word_ratio': np.random.uniform(0.3, 0.6, n_samples // 2),\n",
    "    'punctuation_count': np.random.normal(40, 15, n_samples // 2).clip(10, 100),\n",
    "    'category': ['General'] * (n_samples // 2)\n",
    "}\n",
    "\n",
    "# Combiner et m√©langer\n",
    "df_tech = pd.DataFrame(technical_docs)\n",
    "df_gen = pd.DataFrame(general_docs)\n",
    "df = pd.concat([df_tech, df_gen], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset cr√©√© avec {len(df)} documents\")\n",
    "print(f\"\\nDistribution des classes:\")\n",
    "print(df['category'].value_counts())\n",
    "print(\"\\nAper√ßu des donn√©es:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda",
   "metadata": {},
   "source": [
    "## üîç 2. Analyse exploratoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exploratory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives par cat√©gorie\n",
    "print(\"=\" * 80)\n",
    "print(\"STATISTIQUES PAR CAT√âGORIE\")\n",
    "print(\"=\" * 80)\n",
    "print(df.groupby('category').mean())\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "features = ['text_length', 'avg_word_length', 'num_sentences', \n",
    "            'rare_word_count', 'technical_terms', 'avg_sentence_length']\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    for cat in df['category'].unique():\n",
    "        data = df[df['category'] == cat][feature]\n",
    "        axes[idx].hist(data, alpha=0.6, label=cat, bins=20)\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Fr√©quence')\n",
    "    axes[idx].set_title(f'Distribution: {feature}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-pycaret",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 3. Configuration de PyCaret\n",
    "\n",
    "La fonction `setup()` initialise l'environnement PyCaret et effectue automatiquement le preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pycaret-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de PyCaret\n",
    "clf = setup(\n",
    "    data=df,\n",
    "    target='category',\n",
    "    session_id=42,\n",
    "    train_size=0.8,\n",
    "    normalize=True,  # Normalisation des features\n",
    "    feature_selection=False,  # Pas de s√©lection automatique pour ce demo\n",
    "    remove_multicollinearity=False,\n",
    "    silent=True,  # Moins de output\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ PyCaret configur√© avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-models",
   "metadata": {},
   "source": [
    "## üèÜ 4. Comparaison automatique de mod√®les\n",
    "\n",
    "PyCaret peut comparer automatiquement des dizaines de mod√®les de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-all-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer tous les mod√®les disponibles\n",
    "print(\"Comparaison de tous les mod√®les (peut prendre quelques minutes)...\\n\")\n",
    "best_models = compare_models(\n",
    "    n_select=5,  # S√©lectionner les 5 meilleurs\n",
    "    sort='F1',  # Trier par F1-score\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Comparaison termin√©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-model",
   "metadata": {},
   "source": [
    "## üéØ 5. Cr√©er et entra√Æner le meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-best-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le meilleur mod√®le (bas√© sur la comparaison)\n",
    "# Par exemple, essayons plusieurs mod√®les populaires\n",
    "\n",
    "# Logistic Regression\n",
    "lr = create_model('lr', verbose=False)\n",
    "print(\"Logistic Regression cr√©√©\")\n",
    "\n",
    "# Random Forest\n",
    "rf = create_model('rf', verbose=False)\n",
    "print(\"Random Forest cr√©√©\")\n",
    "\n",
    "# XGBoost\n",
    "xgb = create_model('xgboost', verbose=False)\n",
    "print(\"XGBoost cr√©√©\")\n",
    "\n",
    "# LightGBM\n",
    "lgb = create_model('lightgbm', verbose=False)\n",
    "print(\"LightGBM cr√©√©\")\n",
    "\n",
    "print(\"\\n‚úÖ Tous les mod√®les cr√©√©s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tune-model",
   "metadata": {},
   "source": [
    "## üîß 6. Optimisation des hyperparam√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tune-best",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuner le meilleur mod√®le (XGBoost par exemple)\n",
    "print(\"Optimisation des hyperparam√®tres...\\n\")\n",
    "tuned_xgb = tune_model(\n",
    "    xgb,\n",
    "    optimize='F1',\n",
    "    n_iter=10,  # Nombre d'it√©rations\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Mod√®le optimis√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize",
   "metadata": {},
   "source": [
    "## üìä 7. Visualisations et interpr√©tation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "print(\"Matrice de confusion:\")\n",
    "plot_model(tuned_xgb, plot='confusion_matrix', display_format='streamlit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-auc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC\n",
    "print(\"Courbe ROC:\")\n",
    "plot_model(tuned_xgb, plot='auc', display_format='streamlit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des features\n",
    "print(\"Importance des features:\")\n",
    "plot_model(tuned_xgb, plot='feature', display_format='streamlit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-pr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe Precision-Recall\n",
    "print(\"Courbe Precision-Recall:\")\n",
    "plot_model(tuned_xgb, plot='pr', display_format='streamlit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate",
   "metadata": {},
   "source": [
    "## üìà 8. √âvaluation finale sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation finale\n",
    "print(\"√âvaluation sur l'ensemble de test (hold-out):\")\n",
    "predictions = predict_model(tuned_xgb)\n",
    "print(predictions.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble",
   "metadata": {},
   "source": [
    "## üé≠ 9. Ensemble de mod√®les (optionnel)\n",
    "\n",
    "Combiner plusieurs mod√®les pour am√©liorer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un ensemble (blending)\n",
    "print(\"Cr√©ation d'un ensemble de mod√®les...\\n\")\n",
    "blended = blend_models(\n",
    "    estimator_list=[lr, rf, tuned_xgb],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Ensemble cr√©√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finalize",
   "metadata": {},
   "source": [
    "## üéì 10. Finalisation et export du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finalize-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finaliser le mod√®le (entra√Æner sur toutes les donn√©es)\n",
    "print(\"Finalisation du mod√®le (entra√Ænement sur toutes les donn√©es)...\")\n",
    "final_model = finalize_model(tuned_xgb)\n",
    "print(\"‚úÖ Mod√®le finalis√©!\")\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "print(\"\\nSauvegarde du mod√®le...\")\n",
    "save_model(final_model, 'best_text_classifier')\n",
    "print(\"‚úÖ Mod√®le sauvegard√© sous 'best_text_classifier.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-predict",
   "metadata": {},
   "source": [
    "## üîÆ 11. Charger et utiliser le mod√®le sauvegard√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le mod√®le\n",
    "loaded_model = load_model('best_text_classifier')\n",
    "print(\"‚úÖ Mod√®le charg√©!\")\n",
    "\n",
    "# Pr√©dictions sur de nouvelles donn√©es\n",
    "new_data = pd.DataFrame({\n",
    "    'text_length': [2500, 600, 1800],\n",
    "    'avg_word_length': [8, 5, 7],\n",
    "    'num_sentences': [60, 15, 45],\n",
    "    'rare_word_count': [35, 5, 20],\n",
    "    'technical_terms': [30, 2, 15],\n",
    "    'avg_sentence_length': [28, 12, 22],\n",
    "    'unique_word_ratio': [0.7, 0.4, 0.6],\n",
    "    'punctuation_count': [120, 30, 80]\n",
    "})\n",
    "\n",
    "print(\"\\nPr√©dictions sur nouvelles donn√©es:\")\n",
    "predictions_new = predict_model(loaded_model, data=new_data)\n",
    "print(predictions_new[['prediction_label', 'prediction_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-summary",
   "metadata": {},
   "source": [
    "## üìã 12. R√©sum√© des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les m√©triques du mod√®le\n",
    "print(\"=\" * 80)\n",
    "print(\"R√âSUM√â DES PERFORMANCES DU MEILLEUR MOD√àLE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nMod√®le: {type(final_model).__name__}\")\n",
    "print(f\"\\nM√©triques sur ensemble de validation (CV):\")\n",
    "# Ces m√©triques ont √©t√© affich√©es lors du create_model et tune_model\n",
    "print(\"Voir les r√©sultats ci-dessus pour les m√©triques d√©taill√©es.\")\n",
    "print(\"\\n‚úÖ Mod√®le pr√™t pour la production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise",
   "metadata": {},
   "source": [
    "## üéØ EXERCICE : Votre projet AutoML\n",
    "\n",
    "**Objectif**: Utiliser PyCaret pour une t√¢che de classification ou r√©gression textuelle.\n",
    "\n",
    "**Instructions**:\n",
    "1. Cr√©ez ou utilisez un dataset avec des features extraites de texte\n",
    "2. Configurez PyCaret avec diff√©rentes options de preprocessing\n",
    "3. Comparez tous les mod√®les disponibles\n",
    "4. Optimisez le meilleur mod√®le\n",
    "5. Cr√©ez des visualisations pour interpr√©ter les r√©sultats\n",
    "6. Exportez le mod√®le final\n",
    "\n",
    "**Options avanc√©es √† explorer**:\n",
    "- Feature engineering automatique\n",
    "- S√©lection de features\n",
    "- D√©tection d'outliers\n",
    "- Stacking d'ensembles\n",
    "- Calibration des probabilit√©s\n",
    "\n",
    "**Questions √† r√©pondre**:\n",
    "- Quel mod√®le performe le mieux ?\n",
    "- Quelles features sont les plus importantes ?\n",
    "- Y a-t-il du surapprentissage ?\n",
    "- Comment am√©liorer les performances ?\n",
    "- Le mod√®le est-il pr√™t pour la production ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI\n",
    "# Exemple de structure:\n",
    "\n",
    "# 1. Cr√©er/charger vos donn√©es\n",
    "# my_data = ...\n",
    "\n",
    "# 2. Configuration\n",
    "# clf = setup(data=my_data, target='target_column', ...)\n",
    "\n",
    "# 3. Comparaison\n",
    "# best = compare_models()\n",
    "\n",
    "# 4. Optimisation\n",
    "# tuned = tune_model(best)\n",
    "\n",
    "# 5. Visualisations\n",
    "# plot_model(tuned, plot='confusion_matrix')\n",
    "# plot_model(tuned, plot='feature')\n",
    "\n",
    "# 6. Export\n",
    "# final = finalize_model(tuned)\n",
    "# save_model(final, 'my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## üìù Conclusion\n",
    "\n",
    "Dans cette s√©ance, nous avons appris √† :\n",
    "- Utiliser PyCaret pour le prototypage rapide de mod√®les ML\n",
    "- Comparer automatiquement des dizaines d'algorithmes\n",
    "- Optimiser les hyperparam√®tres avec peu de code\n",
    "- Cr√©er des visualisations pour interpr√©ter les mod√®les\n",
    "- Exporter et r√©utiliser les mod√®les entra√Æn√©s\n",
    "\n",
    "**Avantages de PyCaret** :\n",
    "1. **Rapidit√©**: prototypage en quelques lignes de code\n",
    "2. **Automatisation**: preprocessing, feature engineering, tuning\n",
    "3. **Comparaison**: teste automatiquement de nombreux mod√®les\n",
    "4. **Visualisations**: interpr√©tation facilit√©e\n",
    "5. **Production**: export simple des mod√®les\n",
    "\n",
    "**Limitations** :\n",
    "- Moins de contr√¥le fin que scikit-learn pur\n",
    "- N√©cessite de bonnes features en entr√©e\n",
    "- Peut √™tre lent pour de tr√®s gros datasets\n",
    "- Abstractions peuvent masquer certains probl√®mes\n",
    "\n",
    "**Prochaines √©tapes** :\n",
    "- Essayer PyCaret sur vos propres datasets\n",
    "- Explorer les modules regression, clustering, anomaly detection\n",
    "- Int√©grer PyCaret dans un pipeline de production\n",
    "- Combiner avec deep learning pour le texte brut\n",
    "\n",
    "**Ressources suppl√©mentaires** :\n",
    "- Documentation PyCaret: https://pycaret.org/\n",
    "- Tutoriels: https://pycaret.org/tutorial/\n",
    "- GitHub: https://github.com/pycaret/pycaret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
