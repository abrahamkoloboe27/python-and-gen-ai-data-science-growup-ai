{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca62d5e4",
   "metadata": {},
   "source": [
    "# S√©ance 3 ‚Äî Statsmodels & analyses statistiques de base\n",
    "\n",
    "## üéØ Objectifs\n",
    "- R√©aliser des tests statistiques simples\n",
    "- Comprendre et impl√©menter des r√©gressions lin√©aires pour features diagnostics\n",
    "- Ma√Ætriser les statistiques descriptives avanc√©es\n",
    "- Effectuer des tests d'hypoth√®ses\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Introduction\n",
    "\n",
    "**Statsmodels** est une biblioth√®que Python pour l'estimation de mod√®les statistiques et les tests statistiques. Elle offre des outils complets pour l'analyse de r√©gression, les tests d'hypoth√®ses, et plus encore.\n",
    "\n",
    "**Installation :**\n",
    "```bash\n",
    "pip install statsmodels scipy pandas numpy matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why-stats-tests",
   "metadata": {},
   "source": [
    "## üìñ Pourquoi faire des tests statistiques ?\n",
    "\n",
    "### üéØ L'importance des tests statistiques\n",
    "\n",
    "Les tests statistiques sont essentiels en data science et machine learning pour:\n",
    "\n",
    "1. **Valider les hypoth√®ses** : V√©rifier si nos observations sont dues au hasard ou √† des effets r√©els\n",
    "2. **Prendre des d√©cisions √©clair√©es** : Baser nos choix sur des preuves statistiques plut√¥t que sur l'intuition\n",
    "3. **√âvaluer la fiabilit√©** : Comprendre la confiance que nous pouvons avoir dans nos r√©sultats\n",
    "4. **Comparer des groupes** : D√©terminer si des diff√©rences observ√©es sont significatives\n",
    "5. **Valider les mod√®les** : V√©rifier que les hypoth√®ses de nos mod√®les (comme la r√©gression) sont respect√©es\n",
    "\n",
    "### üìä Types de tests statistiques\n",
    "\n",
    "| Type de test | Objectif | Quand l'utiliser | Exemple |\n",
    "|-------------|----------|------------------|---------|\n",
    "| **Test de normalit√©** | V√©rifier si les donn√©es suivent une distribution normale | Avant d'appliquer des tests param√©triques | Shapiro-Wilk, Kolmogorov-Smirnov |\n",
    "| **Test t (Student)** | Comparer les moyennes de deux groupes | Comparer deux √©chantillons ind√©pendants | Comparer les ventes avant/apr√®s une campagne |\n",
    "| **Test de Chi-2** | Tester l'ind√©pendance entre variables cat√©gorielles | Analyser des tableaux de contingence | Relation entre genre et pr√©f√©rence produit |\n",
    "| **ANOVA** | Comparer les moyennes de 3+ groupes | Comparer plusieurs groupes simultan√©ment | Comparer les performances de 5 algorithmes |\n",
    "| **Test de corr√©lation** | Mesurer la relation entre deux variables | √âvaluer la force d'une relation lin√©aire | Corr√©lation entre temp√©rature et ventes |\n",
    "| **Tests non-param√©triques** | Alternative quand les donn√©es ne sont pas normales | Donn√©es ordinales ou non-normales | Mann-Whitney, Kruskal-Wallis |\n",
    "\n",
    "### üîç Comment interpr√©ter les r√©sultats ?\n",
    "\n",
    "#### La p-value (valeur p)\n",
    "\n",
    "La **p-value** est la probabilit√© d'observer les r√©sultats obtenus (ou plus extr√™mes) si l'hypoth√®se nulle √©tait vraie.\n",
    "\n",
    "| p-value | Interpr√©tation | D√©cision |\n",
    "|---------|---------------|----------|\n",
    "| **p < 0.001** | Tr√®s forte √©vidence contre H‚ÇÄ | ‚≠ê‚≠ê‚≠ê Hautement significatif |\n",
    "| **p < 0.01** | Forte √©vidence contre H‚ÇÄ | ‚≠ê‚≠ê Tr√®s significatif |\n",
    "| **p < 0.05** | √âvidence mod√©r√©e contre H‚ÇÄ | ‚≠ê Significatif (seuil standard) |\n",
    "| **p < 0.10** | √âvidence faible contre H‚ÇÄ | ü§î Marginalement significatif |\n",
    "| **p ‚â• 0.05** | Pas d'√©vidence contre H‚ÇÄ | ‚ùå Non significatif |\n",
    "\n",
    "**Interpr√©tation** :\n",
    "- Si **p < 0.05** : On rejette l'hypoth√®se nulle (H‚ÇÄ) ‚Üí Les diff√©rences sont statistiquement significatives\n",
    "- Si **p ‚â• 0.05** : On ne peut pas rejeter H‚ÇÄ ‚Üí Pas de preuve de diff√©rence significative\n",
    "\n",
    "#### Les hypoth√®ses\n",
    "\n",
    "**Hypoth√®se nulle (H‚ÇÄ)** : \"Il n'y a pas d'effet\" ou \"Pas de diff√©rence entre les groupes\"\n",
    "**Hypoth√®se alternative (H‚ÇÅ)** : \"Il y a un effet\" ou \"Il y a une diff√©rence\"\n",
    "\n",
    "#### Risques d'erreur\n",
    "\n",
    "| Type d'erreur | Description | Symbole | Cons√©quence |\n",
    "|---------------|-------------|---------|-------------|\n",
    "| **Erreur de Type I** | Rejeter H‚ÇÄ alors qu'elle est vraie (faux positif) | Œ± (alpha) | Croire √† un effet qui n'existe pas |\n",
    "| **Erreur de Type II** | Ne pas rejeter H‚ÇÄ alors qu'elle est fausse (faux n√©gatif) | Œ≤ (beta) | Rater un effet qui existe |\n",
    "\n",
    "**Le niveau de signification Œ±** (usuellement 0.05) repr√©sente le risque qu'on accepte de commettre une erreur de Type I.\n",
    "\n",
    "### üìê Statistiques descriptives vs inf√©rentielles\n",
    "\n",
    "| Aspect | Statistiques descriptives | Statistiques inf√©rentielles |\n",
    "|--------|--------------------------|---------------------------|\n",
    "| **Objectif** | R√©sumer et d√©crire les donn√©es | Tirer des conclusions sur la population |\n",
    "| **M√©thodes** | Moyenne, m√©diane, √©cart-type, graphiques | Tests d'hypoth√®ses, intervalles de confiance |\n",
    "| **Question** | \"Que disent mes donn√©es ?\" | \"Puis-je g√©n√©raliser √† la population ?\" |\n",
    "| **Exemple** | \"La moyenne d'√¢ge est 35 ans\" | \"L'√¢ge moyen de la population est entre 33 et 37 ans (95% confiance)\" |\n",
    "\n",
    "### üí° R√®gles d'or\n",
    "\n",
    "1. **Toujours visualiser** les donn√©es avant de tester\n",
    "2. **V√©rifier les hypoth√®ses** du test (normalit√©, homosc√©dasticit√©, etc.)\n",
    "3. **Ne pas confondre** significativit√© statistique et importance pratique\n",
    "4. **Consid√©rer la taille d'effet** en plus de la p-value\n",
    "5. **Ajuster pour les tests multiples** si vous faites plusieurs comparaisons\n",
    "6. **Interpr√©ter avec le contexte** : une diff√©rence significative n'est pas toujours importante en pratique\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## üìä 1. Pr√©paration des donn√©es\n",
    "\n",
    "Nous allons cr√©er un jeu de donn√©es simul√© repr√©sentant des documents avec diff√©rentes caract√©ristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'un dataset de documents\n",
    "np.random.seed(42)\n",
    "n_docs = 500\n",
    "\n",
    "# G√©n√©ration des features\n",
    "longueur = np.random.normal(1000, 300, n_docs).clip(100, 3000)\n",
    "mots_rares = np.random.poisson(20, n_docs)\n",
    "phrases_longues = np.random.normal(15, 5, n_docs).clip(0, 40)\n",
    "niveau_technique = np.random.choice([1, 2, 3, 4, 5], n_docs)\n",
    "\n",
    "# Variable cible : difficult√© (fonction de plusieurs features + bruit)\n",
    "difficulte = (\n",
    "    0.002 * longueur +\n",
    "    0.15 * mots_rares +\n",
    "    0.3 * phrases_longues +\n",
    "    2 * niveau_technique +\n",
    "    np.random.normal(0, 3, n_docs)\n",
    ").clip(1, 100)\n",
    "\n",
    "# Cr√©ation du DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'longueur': longueur,\n",
    "    'mots_rares': mots_rares,\n",
    "    'phrases_longues': phrases_longues,\n",
    "    'niveau_technique': niveau_technique,\n",
    "    'difficulte': difficulte\n",
    "})\n",
    "\n",
    "print(\"Dataset cr√©√© avec succ√®s!\")\n",
    "print(f\"Dimensions: {df.shape}\")\n",
    "print(\"\\nPremi√®res lignes:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-desc",
   "metadata": {},
   "source": [
    "## üìà 2. Statistiques descriptives avanc√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descriptive-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives compl√®tes\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTIQUES DESCRIPTIVES\")\n",
    "print(\"=\" * 60)\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ASYM√âTRIE (SKEWNESS) ET APLATISSEMENT (KURTOSIS)\")\n",
    "print(\"=\" * 60)\n",
    "for col in df.columns:\n",
    "    skew = stats.skew(df[col])\n",
    "    kurt = stats.kurtosis(df[col])\n",
    "    print(f\"{col:20s} | Skewness: {skew:7.3f} | Kurtosis: {kurt:7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlation",
   "metadata": {},
   "source": [
    "## üîó 3. Analyse de corr√©lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corr√©lation\n",
    "corr_matrix = df.corr()\n",
    "print(\"Matrice de corr√©lation:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(len(corr_matrix.columns)))\n",
    "ax.set_yticks(range(len(corr_matrix.columns)))\n",
    "ax.set_xticklabels(corr_matrix.columns, rotation=45, ha='right')\n",
    "ax.set_yticklabels(corr_matrix.columns)\n",
    "\n",
    "# Ajouter les valeurs dans les cellules\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(len(corr_matrix)):\n",
    "        text = ax.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
    "                      ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.title('Matrice de corr√©lation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hypothesis-tests",
   "metadata": {},
   "source": [
    "## üß™ 4. Tests d'hypoth√®ses\n",
    "\n",
    "### Test de normalit√© (Shapiro-Wilk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normality-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de normalit√© pour chaque variable\n",
    "print(\"=\" * 60)\n",
    "print(\"TESTS DE NORMALIT√â (Shapiro-Wilk)\")\n",
    "print(\"=\" * 60)\n",
    "for col in df.columns:\n",
    "    stat, p_value = stats.shapiro(df[col])\n",
    "    is_normal = \"OUI\" if p_value > 0.05 else \"NON\"\n",
    "    print(f\"{col:20s} | p-value: {p_value:.4f} | Normal: {is_normal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ttest",
   "metadata": {},
   "source": [
    "### Test t de Student (comparaison de moyennes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ttest-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer la difficult√© entre documents de niveau technique bas (1-2) et haut (4-5)\n",
    "niveau_bas = df[df['niveau_technique'].isin([1, 2])]['difficulte']\n",
    "niveau_haut = df[df['niveau_technique'].isin([4, 5])]['difficulte']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(niveau_bas, niveau_haut)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST T DE STUDENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Moyenne difficult√© (niveau bas):  {niveau_bas.mean():.2f}\")\n",
    "print(f\"Moyenne difficult√© (niveau haut): {niveau_haut.mean():.2f}\")\n",
    "print(f\"\\nStatistique t: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"\\nConclusion: La diff√©rence est {'significative' if p_value < 0.05 else 'non significative'} (Œ±=0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ols-section",
   "metadata": {},
   "source": [
    "## üìâ 5. R√©gression lin√©aire simple (OLS)\n",
    "\n",
    "### Mod√®le univari√© : longueur ‚Üí difficult√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-ols",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es\n",
    "X = df['longueur']\n",
    "y = df['difficulte']\n",
    "\n",
    "# Ajout de la constante (intercept)\n",
    "X_with_const = sm.add_constant(X)\n",
    "\n",
    "# Estimation du mod√®le\n",
    "model_simple = sm.OLS(y, X_with_const)\n",
    "results_simple = model_simple.fit()\n",
    "\n",
    "# Affichage du r√©sum√©\n",
    "print(results_simple.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-simple-ols",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du mod√®le\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Points observ√©s\n",
    "ax.scatter(X, y, alpha=0.5, label='Donn√©es observ√©es')\n",
    "\n",
    "# Droite de r√©gression\n",
    "x_pred = np.linspace(X.min(), X.max(), 100)\n",
    "X_pred_const = sm.add_constant(x_pred)\n",
    "y_pred = results_simple.predict(X_pred_const)\n",
    "ax.plot(x_pred, y_pred, 'r-', linewidth=2, label='Droite de r√©gression')\n",
    "\n",
    "# Intervalle de confiance\n",
    "predictions = results_simple.get_prediction(X_pred_const)\n",
    "pred_summary = predictions.summary_frame(alpha=0.05)\n",
    "ax.fill_between(x_pred, pred_summary['obs_ci_lower'], pred_summary['obs_ci_upper'],\n",
    "                alpha=0.2, color='red', label='Intervalle de confiance 95%')\n",
    "\n",
    "ax.set_xlabel('Longueur du document', fontsize=12)\n",
    "ax.set_ylabel('Difficult√©', fontsize=12)\n",
    "ax.set_title('R√©gression lin√©aire: Longueur ‚Üí Difficult√©', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n√âquation: Difficult√© = {results_simple.params[0]:.2f} + {results_simple.params[1]:.4f} √ó Longueur\")\n",
    "print(f\"R¬≤ = {results_simple.rsquared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-ols",
   "metadata": {},
   "source": [
    "## üìä 6. R√©gression lin√©aire multiple\n",
    "\n",
    "### Mod√®le multivari√© : toutes les features ‚Üí difficult√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es\n",
    "X_multi = df[['longueur', 'mots_rares', 'phrases_longues', 'niveau_technique']]\n",
    "y_multi = df['difficulte']\n",
    "\n",
    "# Ajout de la constante\n",
    "X_multi_const = sm.add_constant(X_multi)\n",
    "\n",
    "# Estimation du mod√®le\n",
    "model_multi = sm.OLS(y_multi, X_multi_const)\n",
    "results_multi = model_multi.fit()\n",
    "\n",
    "# Affichage du r√©sum√©\n",
    "print(results_multi.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostics",
   "metadata": {},
   "source": [
    "## üîç 7. Diagnostics de r√©gression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regression-diagnostics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques de diagnostic\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. R√©sidus vs valeurs pr√©dites\n",
    "residuals = results_multi.resid\n",
    "fitted = results_multi.fittedvalues\n",
    "axes[0, 0].scatter(fitted, residuals, alpha=0.5)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Valeurs pr√©dites')\n",
    "axes[0, 0].set_ylabel('R√©sidus')\n",
    "axes[0, 0].set_title('R√©sidus vs Valeurs pr√©dites')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Q-Q plot (normalit√© des r√©sidus)\n",
    "sm.qqplot(residuals, line='s', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Q-Q Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Scale-Location (homosc√©dasticit√©)\n",
    "standardized_resid = np.sqrt(np.abs((residuals - residuals.mean()) / residuals.std()))\n",
    "axes[1, 0].scatter(fitted, standardized_resid, alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Valeurs pr√©dites')\n",
    "axes[1, 0].set_ylabel('‚àö|R√©sidus standardis√©s|')\n",
    "axes[1, 0].set_title('Scale-Location')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Histogramme des r√©sidus\n",
    "axes[1, 1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('R√©sidus')\n",
    "axes[1, 1].set_ylabel('Fr√©quence')\n",
    "axes[1, 1].set_title('Distribution des r√©sidus')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## üìã 8. Comparaison des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "comparison = pd.DataFrame({\n",
    "    'Mod√®le': ['Simple (longueur)', 'Multiple (toutes features)'],\n",
    "    'R¬≤': [results_simple.rsquared, results_multi.rsquared],\n",
    "    'R¬≤ ajust√©': [results_simple.rsquared_adj, results_multi.rsquared_adj],\n",
    "    'AIC': [results_simple.aic, results_multi.aic],\n",
    "    'BIC': [results_simple.bic, results_multi.bic],\n",
    "    'RMSE': [\n",
    "        np.sqrt(np.mean(results_simple.resid**2)),\n",
    "        np.sqrt(np.mean(results_multi.resid**2))\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"\\nNote: Plus le R¬≤ est √©lev√©, mieux c'est. Plus l'AIC/BIC est faible, mieux c'est.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise",
   "metadata": {},
   "source": [
    "## üéØ EXERCICE : Votre mod√®le OLS\n",
    "\n",
    "**Objectif**: Cr√©er un mod√®le OLS simplifi√© pour pr√©dire une m√©trique de votre choix.\n",
    "\n",
    "**Instructions**:\n",
    "1. Choisissez une variable cible (par exemple: difficult√©, longueur, etc.)\n",
    "2. S√©lectionnez 2-3 variables explicatives\n",
    "3. Construisez le mod√®le OLS\n",
    "4. Analysez les r√©sultats (coefficients, p-values, R¬≤)\n",
    "5. Cr√©ez les graphiques de diagnostic\n",
    "6. Interpr√©tez les r√©sultats\n",
    "\n",
    "**Questions √† r√©pondre**:\n",
    "- Quelles variables sont significatives ?\n",
    "- Quel est le pouvoir explicatif du mod√®le (R¬≤) ?\n",
    "- Les hypoth√®ses de la r√©gression sont-elles respect√©es ?\n",
    "- Comment am√©liorer le mod√®le ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI\n",
    "# Exemple de structure:\n",
    "\n",
    "# 1. S√©lection des variables\n",
    "# X_ex = df[['variable1', 'variable2']]\n",
    "# y_ex = df['cible']\n",
    "\n",
    "# 2. Ajout de la constante\n",
    "# X_ex_const = sm.add_constant(X_ex)\n",
    "\n",
    "# 3. Estimation du mod√®le\n",
    "# model_ex = sm.OLS(y_ex, X_ex_const)\n",
    "# results_ex = model_ex.fit()\n",
    "\n",
    "# 4. Affichage des r√©sultats\n",
    "# print(results_ex.summary())\n",
    "\n",
    "# 5. Visualisations et diagnostics\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## üìù Conclusion\n",
    "\n",
    "Dans cette s√©ance, nous avons appris √† :\n",
    "- Calculer des statistiques descriptives avanc√©es\n",
    "- Effectuer des tests d'hypoth√®ses (normalit√©, test t)\n",
    "- Construire des mod√®les de r√©gression lin√©aire (simple et multiple)\n",
    "- Diagnostiquer et √©valuer les mod√®les\n",
    "- Interpr√©ter les r√©sultats statistiques\n",
    "\n",
    "**Points cl√©s √† retenir** :\n",
    "1. Les tests statistiques n√©cessitent des hypoth√®ses (ex: normalit√©)\n",
    "2. Le R¬≤ mesure la qualit√© de l'ajustement mais ne garantit pas la causalit√©\n",
    "3. Les diagnostics de r√©gression sont essentiels pour valider les mod√®les\n",
    "4. Un mod√®le simple peut √™tre pr√©f√©rable √† un mod√®le complexe (principe de parcimonie)\n",
    "\n",
    "**Ressources suppl√©mentaires** :\n",
    "- Documentation Statsmodels: https://www.statsmodels.org/\n",
    "- Scipy Stats: https://docs.scipy.org/doc/scipy/reference/stats.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}