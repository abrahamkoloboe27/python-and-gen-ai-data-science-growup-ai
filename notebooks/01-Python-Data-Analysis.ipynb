{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca62d5e4",
   "metadata": {},
   "source": [
    "# Séance 1 — Rappel : Analyse de données avec Pandas (Scraping & préprocessing)\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Fournir une méthode pratique et reproductible pour passer d’un **jeu de fichiers mensuels bruts** (NYC Yellow Taxi) à un **jeu de données tabulaire propre, enrichi et prêt pour de l’analyse ou du machine learning**. À l’issue de la séance, vous saurez : charger et concaténer des fichiers parquet/CSV, nettoyer les valeurs aberrantes, parser et exploiter des timestamps, créer des features temporelles et géographiques, agréger par zone/heure, et exporter des livrables réutilisables.\n",
    "\n",
    "## Description des données\n",
    "\n",
    "Nous utilisons les **fichiers mensuels Yellow Taxi (NYC)** au format Parquet : `yellow_tripdata_{YYYY}-{MM}.parquet`. Le script fourni permet d’itérer sur une plage temporelle (par défaut `2009-01` → `2025-12`) et de récupérer en plus le fichier de référence des zones `taxi_zone_lookup.csv`.\n",
    "Colonnes courantes (exemples) :\n",
    "\n",
    "* `tpep_pickup_datetime`, `tpep_dropoff_datetime` (horodatages)\n",
    "* `PULocationID`, `DOLocationID` (identifiants de zone)\n",
    "* `trip_distance`, `passenger_count` (mesures)\n",
    "* `fare_amount`, `tip_amount`, `total_amount`, `payment_type` (tarification)\n",
    "  Chaque fichier mensuel contient un grand nombre d’enregistrements : pour une session en salle, privilégier un **échantillon** ou un **mois réduit** plutôt que de charger l’intégralité de la plage en mémoire.\n",
    "\n",
    "## Récupération des fichiers\n",
    "\n",
    "Le script de téléchargement utilise les URLs publiques du dataset (`yellow_tripdata_{YYYY}-{MM}.parquet`) et télécharge également `taxi_zone_lookup.csv`. Pour la séance, les options recommandées :\n",
    "\n",
    "* utiliser un **échantillon** (ex. `yellow_tripdata_sample.csv` ou un seul mois), ou\n",
    "* télécharger 1–3 mois représentatifs (p. ex. janvier / juillet / décembre d’une année).\n",
    "  Le script crée les dossiers nécessaires et convertit le lookup CSV en parquet pour accélérer les lectures ultérieures.\n",
    "\n",
    "## Tâches & transformations avec Pandas\n",
    "\n",
    "Les opérations couvertes et démontrées dans le TP :\n",
    "\n",
    "1. **Chargement & inspection**\n",
    "\n",
    "   * `pd.read_parquet` / `pd.read_csv` ; `head()`, `shape`, `dtypes`, comptage NaN.\n",
    "\n",
    "2. **Concaténation incrémentale**\n",
    "\n",
    "   * lire fichier par fichier et concaténer (ou streamer / échantillonner) pour éviter d’épuiser la mémoire.\n",
    "\n",
    "3. **Nettoyage basique**\n",
    "\n",
    "   * suppression des lignes impossibles ou aberrantes : `trip_distance <= 0`, `fare_amount <= 0`, `trip_duration <= 0`.\n",
    "   * normalisation des textes/IDs si nécessaire, gestion des valeurs manquantes (`fillna` / `dropna`).\n",
    "\n",
    "4. **Parsing et gestion des dates**\n",
    "\n",
    "   * conversion en `datetime` (`pd.to_datetime`), calcul de la durée (`dropoff - pickup`), détection d’erreurs de parsing.\n",
    "   * extraction de composantes temporelles : `pickup_hour`, `pickup_day`, `pickup_weekday`, `pickup_month`, `is_night`.\n",
    "\n",
    "5. **Feature engineering tabulaire**\n",
    "\n",
    "   * `fare_per_km = fare_amount / trip_distance` (avec gestion des divisions par zéro).\n",
    "   * `tip_ratio = tip_amount / fare_amount`.\n",
    "   * indicateurs (ex. `is_long_trip`, `is_shared_zone`) et colonnes dérivées (`n_words` style analogies si texte présent).\n",
    "\n",
    "6. **Jointures / merges**\n",
    "\n",
    "   * joindre `taxi_zone_lookup` sur `PULocationID`/`DOLocationID` pour obtenir `pickup_borough`, `pickup_zone` et enrichir l’analyse géographique.\n",
    "\n",
    "7. **Aggregations & groupby**\n",
    "\n",
    "   * agrégations par zone / heure / jour : `count`, `mean(trip_distance)`, `median(fare_amount)`, `mean(tip_ratio)`, `max(trip_duration)`.\n",
    "   * création de tables résumées utiles pour visualisations et features d’agrégation.\n",
    "\n",
    "8. **Opérations ligne-à-ligne**\n",
    "\n",
    "   * usage ponctuel de `apply` pour transformations personnalisées (avec mise en garde sur la performance : préférer les opérations vectorisées quand c’est possible).\n",
    "\n",
    "9. **Export**\n",
    "\n",
    "   * export final en CSV/Parquet (`cleaned_trips.csv` / `cleaned_trips.parquet`) prêt pour modélisation ou ingestion dans un pipeline ML.\n",
    "\n",
    "## Livrables attendus\n",
    "\n",
    "* `s1_pandas.ipynb` : notebook bien commenté (Markdown + cellules de code) avec étapes reproductibles.\n",
    "* `cleaned_trips.csv` ou `cleaned_trips.parquet` : dataset nettoyé et réduit aux colonnes pertinentes pour ML.\n",
    "* `summary_by_zone.csv` : table résumé par zone (nombre de trajets, distance moyenne, tarif moyen, ratio pourboire).\n",
    "* Optional : notebook ou script d’échantillonnage si traitement complet trop lourd.\n",
    "\n",
    "## Bonnes pratiques et remarques opérationnelles\n",
    "\n",
    "* **Échantillonnage** : pour la classe, limiter le volume (100k–500k lignes) afin de conserver interactivité.\n",
    "* **Mémoire** : lire fichier par fichier, utiliser `dtype` explicites et `usecols` pour réduire la charge mémoire.\n",
    "* **Robustesse** : toujours vérifier `dtypes` après lecture et utiliser `indicator=True` lors des merges pour diagnostiquer les clés non appariées.\n",
    "* **Chunking des textes** : si vous ajoutez des colonnes textuelles volumineuses (ex. notes), découper avant export pour embeddings.\n",
    "* **Reproductibilité** : versionner le script de téléchargement et enregistrer la liste des fichiers sources (hashs ou timestamps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a0728",
   "metadata": {},
   "source": [
    "# 1 -  Script de téléchargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import os\n",
    "NYC_TRIPS_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{}-{}.parquet\"\n",
    "DATSET_FOLDER = 'yellow_tripdata'\n",
    "TAXI_ZONE_URL = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "def verify_if_file_already_downloaded(file_path: str) -> bool:\n",
    "    \"\"\"\n",
    "        Verify if file already downloaded\n",
    "        Args:\n",
    "            file_path (str): File path\n",
    "        Returns:\n",
    "            bool: True if file already downloaded, False otherwise\n",
    "    \"\"\"\n",
    "    return os.path.exists(file_path)\n",
    "\n",
    "def format_url(year: str, month: str) -> str:\n",
    "    \"\"\"\n",
    "        Format URL\n",
    "        Args:\n",
    "            year (str): Year\n",
    "            month (str): Month\n",
    "        Returns:\n",
    "            str: Formatted URL\n",
    "    \"\"\"\n",
    "    return NYC_TRIPS_URL.format(year, month)\n",
    "\n",
    "def generate_month_range(start_month : str = '2009-01', \n",
    "                         end_month : str = '2025-12'\n",
    "                        ) -> list:\n",
    "    \"\"\"\n",
    "        Generate month range\n",
    "        Args:\n",
    "            start_month (str): Start month\n",
    "            end_month (str): End month\n",
    "        Returns:\n",
    "            list: Month range\n",
    "    \"\"\"\n",
    "    start_year, start_month = int(start_month[:4]), int(start_month[5:])\n",
    "    end_year, end_month = int(end_month[:4]), int(end_month[5:])  # Correction ici: end_month[5:] au lieu de end_month[4:]\n",
    "    month_range = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(start_month if year == start_year else 1, end_month + 1 if year == end_year else 13):\n",
    "            month_range.append(f\"{year}-{month:02d}\")\n",
    "    return month_range\n",
    "def download_data(url: str, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "        Download data from URL\n",
    "        Args:\n",
    "            url (str): URL\n",
    "            file_path (str): File path\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data from {url} to {file_path}\")\n",
    "    response = requests.get(url)\n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Data downloaded from {url} with status code {response.status_code}\")\n",
    "    elif response.status_code == 403 : \n",
    "        print(f\"File {url} not found, status code {response.status_code}\")\n",
    "        raise Exception(f\"File {url} not found, status code {response.status_code}\")\n",
    "    else:\n",
    "        print(f\"Failed to download data from {url} with status code {response.status_code}\")\n",
    "        raise Exception(f\"Failed to download data from {url} with status code {response.status_code}\")\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Data downloaded from {url} to {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "def download_data_for_month(year: str, month: str, download_dir: str = f\"./data/{DATSET_FOLDER}\") -> str:\n",
    "    \"\"\"\n",
    "        Download data for month\n",
    "        Args:\n",
    "            year (str): Year\n",
    "            month (str): Month\n",
    "            download_dir (str): Download directory\n",
    "        Returns:\n",
    "            str: File path\n",
    "    \"\"\"\n",
    "    url = format_url(year, month)\n",
    "    file_path = os.path.join(download_dir, f\"{year}-{month}.parquet\")\n",
    "    if verify_if_file_already_downloaded(file_path):\n",
    "        print(f\"File {file_path} already downloaded, skipping download\")\n",
    "        return file_path\n",
    "    return download_data(url, file_path)\n",
    "\n",
    "def download_data_month_to_month(\n",
    "                                start_month : str = '2009-01', \n",
    "                                end_month : str = '2025-12', \n",
    "                                download_dir: str = f\"./data/{DATSET_FOLDER}\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "        Download data month to month\n",
    "        Args:\n",
    "            start_month (str): Start month\n",
    "            end_month (str): End month\n",
    "            download_dir (str): Download directory\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data from {start_month} to {end_month} to {download_dir}\")\n",
    "    month_range = generate_month_range(start_month, end_month)\n",
    "    for month in month_range:\n",
    "        year, month_num = month.split('-')\n",
    "        try:\n",
    "            download_data_for_month(year, month_num, download_dir)\n",
    "            print(f\"Successfully downloaded data for {year}-{month_num} to {download_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download data for {year}-{month_num}, error: {e}\")\n",
    "    print(f\"Downloaded data from {start_month} to {end_month} to {download_dir}\")\n",
    "    \n",
    "def download_taxi_zones() -> None:\n",
    "    \"\"\"\n",
    "    Télécharge le fichier des zones de taxi, le convertit en parquet et supprime le CSV.\n",
    "    \"\"\"\n",
    "    url = TAXI_ZONE_URL\n",
    "    csv_path = \"./data/yellow_tripdata/taxi_zones.csv\"\n",
    "    parquet_path = \"./data/yellow_tripdata/taxi_zones.parquet\"\n",
    "    \n",
    "    # Création du dossier si nécessaire\n",
    "    os.makedirs(\"./data/yellow_tripdata\", exist_ok=True)\n",
    "    \n",
    "    # Téléchargement du fichier\n",
    "    print(f\"Téléchargement des zones de taxi depuis {url}\")\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Échec du téléchargement des zones de taxi. Code: {response.status_code}\")\n",
    "        return\n",
    "        \n",
    "    # Sauvegarde du CSV\n",
    "    with open(csv_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Fichier CSV sauvegardé: {csv_path}\")\n",
    "    \n",
    "    # Conversion en parquet\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df.to_parquet(parquet_path)\n",
    "        print(f\"Fichier converti en parquet: {parquet_path}\")\n",
    "        \n",
    "        # Suppression du CSV\n",
    "        os.remove(csv_path)\n",
    "        print(\"Fichier CSV supprimé\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la conversion: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d44ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from 2023-01 to 2026-01 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet to ./data/yellow_tripdata/2023-01.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet to ./data/yellow_tripdata/2023-01.parquet\n",
      "Successfully downloaded data for 2023-01 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet to ./data/yellow_tripdata/2023-02.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet to ./data/yellow_tripdata/2023-02.parquet\n",
      "Successfully downloaded data for 2023-02 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet to ./data/yellow_tripdata/2023-03.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet to ./data/yellow_tripdata/2023-03.parquet\n",
      "Successfully downloaded data for 2023-03 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet to ./data/yellow_tripdata/2023-04.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet to ./data/yellow_tripdata/2023-04.parquet\n",
      "Successfully downloaded data for 2023-04 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet to ./data/yellow_tripdata/2023-05.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet to ./data/yellow_tripdata/2023-05.parquet\n",
      "Successfully downloaded data for 2023-05 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet to ./data/yellow_tripdata/2023-06.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet to ./data/yellow_tripdata/2023-06.parquet\n",
      "Successfully downloaded data for 2023-06 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet to ./data/yellow_tripdata/2023-07.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet to ./data/yellow_tripdata/2023-07.parquet\n",
      "Successfully downloaded data for 2023-07 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet to ./data/yellow_tripdata/2023-08.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet to ./data/yellow_tripdata/2023-08.parquet\n",
      "Successfully downloaded data for 2023-08 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet to ./data/yellow_tripdata/2023-09.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet to ./data/yellow_tripdata/2023-09.parquet\n",
      "Successfully downloaded data for 2023-09 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet to ./data/yellow_tripdata/2023-10.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet to ./data/yellow_tripdata/2023-10.parquet\n",
      "Successfully downloaded data for 2023-10 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet to ./data/yellow_tripdata/2023-11.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet to ./data/yellow_tripdata/2023-11.parquet\n",
      "Successfully downloaded data for 2023-11 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet to ./data/yellow_tripdata/2023-12.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet to ./data/yellow_tripdata/2023-12.parquet\n",
      "Successfully downloaded data for 2023-12 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet to ./data/yellow_tripdata/2024-01.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet to ./data/yellow_tripdata/2024-01.parquet\n",
      "Successfully downloaded data for 2024-01 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet to ./data/yellow_tripdata/2024-02.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet to ./data/yellow_tripdata/2024-02.parquet\n",
      "Successfully downloaded data for 2024-02 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet to ./data/yellow_tripdata/2024-03.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet to ./data/yellow_tripdata/2024-03.parquet\n",
      "Successfully downloaded data for 2024-03 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet to ./data/yellow_tripdata/2024-04.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet to ./data/yellow_tripdata/2024-04.parquet\n",
      "Successfully downloaded data for 2024-04 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet to ./data/yellow_tripdata/2024-05.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet to ./data/yellow_tripdata/2024-05.parquet\n",
      "Successfully downloaded data for 2024-05 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet to ./data/yellow_tripdata/2024-06.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet to ./data/yellow_tripdata/2024-06.parquet\n",
      "Successfully downloaded data for 2024-06 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet to ./data/yellow_tripdata/2024-07.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet to ./data/yellow_tripdata/2024-07.parquet\n",
      "Successfully downloaded data for 2024-07 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet to ./data/yellow_tripdata/2024-08.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet to ./data/yellow_tripdata/2024-08.parquet\n",
      "Successfully downloaded data for 2024-08 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-09.parquet to ./data/yellow_tripdata/2024-09.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-09.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-09.parquet to ./data/yellow_tripdata/2024-09.parquet\n",
      "Successfully downloaded data for 2024-09 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet to ./data/yellow_tripdata/2024-10.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet to ./data/yellow_tripdata/2024-10.parquet\n",
      "Successfully downloaded data for 2024-10 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet to ./data/yellow_tripdata/2024-11.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet to ./data/yellow_tripdata/2024-11.parquet\n",
      "Successfully downloaded data for 2024-11 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-12.parquet to ./data/yellow_tripdata/2024-12.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-12.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-12.parquet to ./data/yellow_tripdata/2024-12.parquet\n",
      "Successfully downloaded data for 2024-12 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet to ./data/yellow_tripdata/2025-01.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet to ./data/yellow_tripdata/2025-01.parquet\n",
      "Successfully downloaded data for 2025-01 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-02.parquet to ./data/yellow_tripdata/2025-02.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-02.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-02.parquet to ./data/yellow_tripdata/2025-02.parquet\n",
      "Successfully downloaded data for 2025-02 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-03.parquet to ./data/yellow_tripdata/2025-03.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-03.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-03.parquet to ./data/yellow_tripdata/2025-03.parquet\n",
      "Successfully downloaded data for 2025-03 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-04.parquet to ./data/yellow_tripdata/2025-04.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-04.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-04.parquet to ./data/yellow_tripdata/2025-04.parquet\n",
      "Successfully downloaded data for 2025-04 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-05.parquet to ./data/yellow_tripdata/2025-05.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-05.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-05.parquet to ./data/yellow_tripdata/2025-05.parquet\n",
      "Successfully downloaded data for 2025-05 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-06.parquet to ./data/yellow_tripdata/2025-06.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-06.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-06.parquet to ./data/yellow_tripdata/2025-06.parquet\n",
      "Successfully downloaded data for 2025-06 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-07.parquet to ./data/yellow_tripdata/2025-07.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-07.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-07.parquet to ./data/yellow_tripdata/2025-07.parquet\n",
      "Successfully downloaded data for 2025-07 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-08.parquet to ./data/yellow_tripdata/2025-08.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-08.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-08.parquet to ./data/yellow_tripdata/2025-08.parquet\n",
      "Successfully downloaded data for 2025-08 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-09.parquet to ./data/yellow_tripdata/2025-09.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-09.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-09.parquet to ./data/yellow_tripdata/2025-09.parquet\n",
      "Successfully downloaded data for 2025-09 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-10.parquet to ./data/yellow_tripdata/2025-10.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-10.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-10.parquet to ./data/yellow_tripdata/2025-10.parquet\n",
      "Successfully downloaded data for 2025-10 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-11.parquet to ./data/yellow_tripdata/2025-11.parquet\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-11.parquet with status code 200\n",
      "Data downloaded from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-11.parquet to ./data/yellow_tripdata/2025-11.parquet\n",
      "Successfully downloaded data for 2025-11 to ./data/yellow_tripdata\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-12.parquet to ./data/yellow_tripdata/2025-12.parquet\n",
      "File https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-12.parquet not found, status code 403\n",
      "Failed to download data for 2025-12, error: File https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-12.parquet not found, status code 403\n",
      "Downloading data from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2026-01.parquet to ./data/yellow_tripdata/2026-01.parquet\n",
      "File https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2026-01.parquet not found, status code 403\n",
      "Failed to download data for 2026-01, error: File https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2026-01.parquet not found, status code 403\n",
      "Downloaded data from 2023-01 to 2026-01 to ./data/yellow_tripdata\n"
     ]
    }
   ],
   "source": [
    "download_data_month_to_month(start_month='2023-01', end_month='2026-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b65477",
   "metadata": {},
   "source": [
    "## Concaténer tous les fichiers mensuels en un seul DataFrame Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4cd531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01.parquet: (3066766, 19)\n",
      "2023-02.parquet: (2913955, 19)\n",
      "2023-03.parquet: (3403766, 19)\n",
      "2023-04.parquet: (3288250, 19)\n",
      "2023-05.parquet: (3513649, 19)\n",
      "2023-06.parquet: (3307234, 19)\n",
      "2023-07.parquet: (2907108, 19)\n",
      "2023-08.parquet: (2824209, 19)\n",
      "2023-09.parquet: (2846722, 19)\n",
      "2023-10.parquet: (3522285, 19)\n",
      "2023-11.parquet: (3339715, 19)\n",
      "2023-12.parquet: (3376567, 19)\n",
      "2024-01.parquet: (2964624, 19)\n",
      "2024-02.parquet: (3007526, 19)\n",
      "2024-03.parquet: (3582628, 19)\n",
      "2024-04.parquet: (3514289, 19)\n",
      "2024-05.parquet: (3723833, 19)\n",
      "2024-06.parquet: (3539193, 19)\n",
      "2024-07.parquet: (3076903, 19)\n",
      "2024-08.parquet: (2979183, 19)\n",
      "2024-09.parquet: (3633030, 19)\n",
      "2024-10.parquet: (3833771, 19)\n",
      "2024-11.parquet: (3646369, 19)\n",
      "2024-12.parquet: (3668371, 19)\n",
      "2025-01.parquet: (3475226, 20)\n",
      "2025-02.parquet: (3577543, 20)\n",
      "2025-03.parquet: (4145257, 20)\n",
      "2025-04.parquet: (3970553, 20)\n",
      "2025-05.parquet: (4591845, 20)\n",
      "2025-06.parquet: (4322960, 20)\n",
      "2025-07.parquet: (3898963, 20)\n",
      "2025-08.parquet: (3574091, 20)\n",
      "2025-09.parquet: (4251015, 20)\n",
      "2025-10.parquet: (4428699, 20)\n",
      "2025-11.parquet: (4181444, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_list = []\n",
    "for file in sorted(os.listdir(f'./data/{DATSET_FOLDER}')):\n",
    "    if file.endswith('.parquet'):\n",
    "        df = pd.read_parquet(os.path.join(f'./data/{DATSET_FOLDER}', file))\n",
    "        df_list.append(df)\n",
    "        print(f\"{file}: {df.shape}\")\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "print(f\"Combined DataFrame shape: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26048259",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_parquet('./data/cleaned/combined_yellow_tripdata_2023_2026.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d08e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
